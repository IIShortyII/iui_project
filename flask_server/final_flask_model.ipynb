{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UobcW5sUZEui"
      },
      "source": [
        "###**Summary**\n",
        "\n",
        "* Import important libraries \n",
        "* Connect to Google Drive\n",
        "* Load model and save model as pickle file in temporary folder\n",
        "* Start flask server \n",
        "* Retrieve image from flask server and save it in temporary folder\n",
        "* Retrieve image from Google Drive and \n",
        "  * Preprocess image\n",
        "  * Predict image \n",
        "* Send back prediction to flask server \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXoWm0gpXdX4"
      },
      "source": [
        "###**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djUEKJAPnkT9",
        "outputId": "aa126c67-5f38-4d8b-b831-d3061c676e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from flask_ngrok) (2.25.1)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.8/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->flask_ngrok) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->flask_ngrok) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Installing collected packages: flask_ngrok\n",
            "Successfully installed flask_ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install flask_ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yR1Acs72UVxI"
      },
      "outputs": [],
      "source": [
        "# for building and training the model \n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "import keras\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.python.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils.generic_utils import NoopLoadingScope\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import tensorflow_datasets as tfds\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline\n",
        "\n",
        "# for importing saved model \n",
        "from tensorflow.keras import models\n",
        "\n",
        "# for displaying pictures from storage/Google Drive\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# for flask server\n",
        "import flask\n",
        "from flask import Flask, render_template, request, Response, jsonify\n",
        "import pickle\n",
        "import werkzeug\n",
        "from flask_ngrok import run_with_ngrok \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# for Google Drive connection\n",
        "from google.colab import drive\n",
        "\n",
        "# to find out IP address \n",
        "import socket\n",
        "\n",
        "# to transform predictions from nested numpy array to float with two decimals \n",
        "import math\n",
        "\n",
        "# to jsonify for sending the transformed numpy.float32 \n",
        "# that we converted to a regular Python float before \n",
        "# in order to send the drunkenness score to the server \n",
        "# and have the Android app receive the drunkenness score as json in order to be interpretable \n",
        "import json "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG40N0FtzZV1"
      },
      "source": [
        "###**Connect to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIx-ySvzp0N7",
        "outputId": "4c3094da-2025-494e-a157-e98e1cd6468f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google Drive\n",
        "# More information see https://towardsdatascience.com/different-ways-to-connect-google-drive-to-a-google-colab-notebook-pt-1-de03433d2f7a\n",
        "# /content is the root folder of Google Colab and has to be appended to all paths used in the notebook\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSmfBOu7lIF8"
      },
      "source": [
        "###**Load model and save model as pickle file in temporary folder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of35KBNu7x1F"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "# model = models.load_model('/content/drive/My Drive/IUI/Drunkometer/Drunkmodel.h5')\n",
        "drunkmodel = models.load_model('/content/drive/My Drive/IUI/Drunkometer/PretrainedDrunkmodel_tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6_z7P1ynfK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe05380-5b8b-48f8-b527-5f92340dfc33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# save model as pickle file IN THE GOOGLE DRIVE TEMPORARY FOLDER!\n",
        "pickle.dump(drunkmodel, open('drunkmodel.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IwOYrQpdFaQ"
      },
      "source": [
        "###**Start flask server**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yUssLkEqI2y"
      },
      "outputs": [],
      "source": [
        "# https://www.geeksforgeeks.org/how-to-run-flask-app-on-google-colab/amp/ \n",
        "# Google Colab provides a VM(virtual machine) so we cannot access the localhost\n",
        "# (all it does it route it to our local machineâ€™s localhost) \n",
        "# as we do on our local machine when running a local web server. \n",
        "# What we can do is expose it to a public URL using the Python library flask-ngrok.\n",
        "\n",
        "# https://medium.datadriveninvestor.com/machine-learning-model-deployment-using-flask-in-google-colab-1f718693a3c0\n",
        "# We first run the flask app and start ngrok when the app is running then load the model using pickle. \n",
        "# After that, we will create a GET method and return the root page using the render_template. \n",
        "# We will define the home function for getting the values from the page so that we can then predict.\n",
        "\n",
        "app = Flask(__name__) \n",
        "run_with_ngrok(app)\n",
        "model = pickle.load(open('drunkmodel.pkl', 'rb'))\n",
        "\n",
        "#Run and then insert http://0ae5-34-145-159-223.ngrok.io in Android app     \n",
        "# RETRIEVE IMAGE FROM GOOGLE DRIVE, PREPROCESS AND PREDICT \n",
        "def prepare_image(file):\n",
        "  img_path = '/content/'\n",
        "  # OR IF PIC STORED IN GOOGLE DRIVE img_path = '/content/drive/My Drive/IUI/Drunkometer/'\n",
        "  img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "  return tf.keras.applications.vgg16.preprocess_input(img_array_expanded_dims)\n",
        "\n",
        "def predict():\n",
        "  preprocessed_image = prepare_image('drunkometer_selfie.jpeg')\n",
        "  predictions = drunkmodel.predict(preprocessed_image)\n",
        "  #extract drunk score from nested numpy array \n",
        "  drunkprediction = predictions[0,0]\n",
        "  floatdrunkprediction = float(drunkprediction)\n",
        "  ##roundedfloatdrunkprediction = round(floatdrunkprediction, 4)\n",
        "  ##print(roundedfloatdrunkprediction)\n",
        "  jsonfloatdrunkprediction = json.dumps(floatdrunkprediction)\n",
        "  print(jsonfloatdrunkprediction)\n",
        "  return jsonfloatdrunkprediction\n",
        "  ##numpy.float32 is returned\n",
        "  ##return jsonify(drunkprediction)\n",
        "\n",
        "# RETRIEVE IMAGE FROM FLASK SERVER \n",
        "@app.route('/', methods=['POST'])\n",
        "def handle_request():\n",
        "  imagefile = flask.request.files['image']\n",
        "  filename = werkzeug.utils.secure_filename(imagefile.filename)\n",
        "  print(\"\\nReceived image File name: \" + imagefile.filename)\n",
        "  imagefile.save(filename)\n",
        "  prediction = predict()\n",
        "  headers = {'Content-Type': 'application/json'}\n",
        "  return Response(prediction, headers=headers)\n",
        "  #return jsonify(prediction)\n",
        "  ##headers = {'Content-Type': 'text/plain'}\n",
        "  ##return Response(prediction, headers=headers)\n",
        "  ##return Response(prediction, mimetype='text/plain')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rG40N0FtzZV1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}